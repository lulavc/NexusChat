# Project: Enhanced Ollama Chat Interface
# Structure and Implementation Guide

"""
Project Structure:
ollama_chat/
├── src/
│   ├── gui/
│   ├── backend/
│   ├── models/
│   └── utils/
├── tests/
├── resources/
├── docs/
└── scripts/
"""

# requirements.txt
"""
aiohttp==3.9.1
customtkinter==5.2.1
markdown2==2.4.10
python-dateutil==2.8.2
sqlalchemy==2.0.23
pygments==2.17.2
aiosqlite==0.19.0
pillow==10.1.0
pytest==7.4.3
pytest-asyncio==0.21.1
black==23.11.0
pylint==3.0.2
"""

# src/models/base.py
from dataclasses import dataclass
from datetime import datetime
from typing import Optional, List, Dict
import uuid

@dataclass
class BaseModel:
    id: str = uuid.uuid4().hex
    created_at: datetime = datetime.now()
    updated_at: datetime = datetime.now()
    metadata: Optional[Dict] = None

# src/models/message.py
from dataclasses import dataclass
from .base import BaseModel
from enum import Enum

class MessageRole(Enum):
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"

@dataclass
class Message(BaseModel):
    content: str
    role: MessageRole
    model: str
    parent_id: Optional[str] = None
    session_id: Optional[str] = None
    tokens: Optional[int] = None
    processed: bool = False

# src/models/chat_session.py
from dataclasses import dataclass
from typing import List
from .base import BaseModel
from .message import Message

@dataclass
class ChatSession(BaseModel):
    name: str
    model: str
    messages: List[Message]
    system_prompt: Optional[str] = None
    active: bool = True

# src/backend/ollama_client.py
import aiohttp
import json
import logging
from typing import AsyncGenerator, List, Optional
from ..models.message import Message, MessageRole

class OllamaClient:
    def __init__(self, host: str = "http://localhost:11434"):
        self.host = host
        self.logger = logging.getLogger(__name__)
        self._session: Optional[aiohttp.ClientSession] = None

    async def _get_session(self) -> aiohttp.ClientSession:
        if self._session is None:
            self._session = aiohttp.ClientSession()
        return self._session

    async def list_models(self) -> List[str]:
        """Fetch available models from Ollama server"""
        session = await self._get_session()
        async with session.get(f"{self.host}/api/tags") as response:
            data = await response.json()
            return [model["name"] for model in data["models"]]

    async def generate_stream(
        self, 
        prompt: str, 
        model: str, 
        system_prompt: Optional[str] = None
    ) -> AsyncGenerator[str, None]:
        """Generate streaming response from model"""
        session = await self._get_session()
        
        data = {
            "model": model,
            "prompt": prompt,
            "stream": True
        }
        if system_prompt:
            data["system"] = system_prompt

        async with session.post(f"{self.host}/api/generate", json=data) as response:
            async for line in response.content:
                if line:
                    try:
                        chunk = json.loads(line)
                        if "response" in chunk:
                            yield chunk["response"]
                    except json.JSONDecodeError as e:
                        self.logger.error(f"Error decoding response: {e}")

# src/backend/chat_manager.py
from typing import Optional, List, Dict
import asyncio
from ..models.chat_session import ChatSession
from ..models.message import Message, MessageRole
from .ollama_client import OllamaClient
from .storage_manager import StorageManager

class ChatManager:
    def __init__(self):
        self.ollama = OllamaClient()
        self.storage = StorageManager()
        self.active_sessions: Dict[str, ChatSession] = {}
        self.current_session: Optional[ChatSession] = None
        self.message_queue = asyncio.Queue()

    async def create_session(
        self, 
        name: str, 
        model: str, 
        system_prompt: Optional[str] = None
    ) -> ChatSession:
        """Create new chat session"""
        session = ChatSession(
            name=name,
            model=model,
            messages=[],
            system_prompt=system_prompt
        )
        self.active_sessions[session.id] = session
        self.current_session = session
        await self.storage.save_session(session)
        return session

    async def send_message(
        self, 
        content: str, 
        session_id: Optional[str] = None
    ) -> AsyncGenerator[Message, None]:
        """Send message and get streaming response"""
        session = self._get_session(session_id)
        
        # Create user message
        user_msg = Message(
            content=content,
            role=MessageRole.USER,
            model=session.model,
            session_id=session.id
        )
        session.messages.append(user_msg)
        await self.storage.save_message(user_msg)
        
        # Get streaming response
        assistant_msg = Message(
            content="",
            role=MessageRole.ASSISTANT,
            model=session.model,
            session_id=session.id,
            parent_id=user_msg.id
        )
        
        async for chunk in self.ollama.generate_stream(
            prompt=content,
            model=session.model,
            system_prompt=session.system_prompt
        ):
            assistant_msg.content += chunk
            yield assistant_msg
        
        session.messages.append(assistant_msg)
        await self.storage.save_message(assistant_msg)

    def _get_session(self, session_id: Optional[str] = None) -> ChatSession:
        """Get active session"""
        if session_id:
            if session_id not in self.active_sessions:
                raise ValueError(f"Session {session_id} not found")
            return self.active_sessions[session_id]
        if not self.current_session:
            raise ValueError("No active session")
        return self.current_session

# src/gui/app.py
import customtkinter as ctk
from .chat_window import ChatWindow
from .sidebar import Sidebar
from ..backend.chat_manager import ChatManager

class App(ctk.CTk):
    def __init__(self):
        super().__init__()
        
        # Configure window
        self.title("Enhanced Ollama Chat")
        self.geometry("1200x800")
        
        # Initialize backend
        self.chat_manager = ChatManager()
        
        # Configure grid
        self.grid_rowconfigure(0, weight=1)
        self.grid_columnconfigure(1, weight=1)
        
        # Create components
        self.sidebar = Sidebar(self)
        self.chat_window = ChatWindow(self)
        
        # Layout components
        self.sidebar.grid(row=0, column=0, sticky="nswe", padx=10, pady=10)
        self.chat_window.grid(row=0, column=1, sticky="nswe", padx=10, pady=10)
        
        # Bind events
        self.sidebar.bind_events()
        self.chat_window.bind_events()

# src/gui/chat_window.py
import customtkinter as ctk
from typing import Optional
from ..models.message import Message
from .message_bubble import MessageBubble

class ChatWindow(ctk.CTkFrame):
    def __init__(self, master):
        super().__init__(master)
        
        # Configure grid
        self.grid_rowconfigure(0, weight=1)
        self.grid_columnconfigure(0, weight=1)
        
        # Create components
        self.messages_frame = ctk.CTkScrollableFrame(self)
        self.input_frame = ctk.CTkFrame(self)
        self.input_field = ctk.CTkTextbox(self.input_frame, height=100)
        self.send_button = ctk.CTkButton(
            self.input_frame, 
            text="Send", 
            command=self.send_message
        )
        
        # Layout components
        self.messages_frame.grid(row=0, column=0, sticky="nswe", padx=5, pady=5)
        self.input_frame.grid(row=1, column=0, sticky="ew", padx=5, pady=5)
        self.input_field.pack(side="left", fill="both", expand=True, padx=5)
        self.send_button.pack(side="right", padx=5)
        
        # Initialize message bubbles list
        self.message_bubbles = []

    def add_message(self, message: Message):
        """Add new message bubble"""
        bubble = MessageBubble(
            self.messages_frame, 
            message=message
        )
        self.message_bubbles.append(bubble)
        bubble.pack(fill="x", padx=5, pady=2)
        
        # Scroll to bottom
        self.messages_frame._parent_canvas.yview_moveto(1.0)

    async def send_message(self):
        """Send message and handle response"""
        content = self.input_field.get("1.0", "end-1c").strip()
        if not content:
            return
            
        # Clear input
        self.input_field.delete("1.0", "end")
        
        try:
            async for response in self.master.chat_manager.send_message(content):
                # Update or create response bubble
                if not self.message_bubbles or self.message_bubbles[-1].message.id != response.id:
                    self.add_message(response)
                else:
                    self.message_bubbles[-1].update_content(response.content)
        except Exception as e:
            # Show error in chat
            error_msg = Message(
                content=f"Error: {str(e)}",
                role="system",
                model="system"
            )
            self.add_message(error_msg)

# src/main.py
import asyncio
import logging
from gui.app import App
from utils.logger import setup_logger

async def main():
    # Setup logging
    setup_logger()
    logger = logging.getLogger(__name__)
    
    try:
        # Initialize and run application
        app = App()
        app.mainloop()
    except Exception as e:
        logger.error(f"Application error: {e}", exc_info=True)
        raise

if __name__ == "__main__":
    asyncio.run(main())